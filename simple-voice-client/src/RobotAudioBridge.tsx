/**
 * Robot Audio Bridge - å°† Agent éŸ³é¢‘è½¬å‘åˆ°æœºå™¨äºº
 * 
 * æ‹¦æˆª LiveKit è¿œç¨‹éŸ³é¢‘è½¨é“ï¼Œè½¬æ¢ä¸º PCM æ•°æ®ï¼Œé€šè¿‡ WebSocket å‘é€åˆ°æœºå™¨äººã€‚
 */

import { useEffect, useRef, useCallback, useState } from 'react'
import { useRoomContext } from '@livekit/components-react'
import { Track, RemoteTrack, RemoteAudioTrack, RoomEvent } from 'livekit-client'

// æœºå™¨äºº WebSocket é…ç½®
const ROBOT_WS_URL = 'ws://192.168.0.13:8765'

// éŸ³é¢‘é…ç½®ï¼ˆç›®æ ‡æ ¼å¼ï¼š16kHz, å•å£°é“, 16bitï¼‰
const TARGET_SAMPLE_RATE = 16000

interface RobotAudioBridgeState {
    connected: boolean
    error: string | null
    bytesSent: number
}

/**
 * éŸ³é¢‘é‡é‡‡æ ·å™¨
 * å°†ä»»æ„é‡‡æ ·ç‡è½¬æ¢ä¸º 16kHz
 */
function resampleAudio(
    inputBuffer: Float32Array,
    inputSampleRate: number,
    outputSampleRate: number
): Float32Array {
    if (inputSampleRate === outputSampleRate) {
        return inputBuffer
    }

    const ratio = inputSampleRate / outputSampleRate
    const outputLength = Math.floor(inputBuffer.length / ratio)
    const output = new Float32Array(outputLength)

    for (let i = 0; i < outputLength; i++) {
        const srcIndex = i * ratio
        const srcIndexFloor = Math.floor(srcIndex)
        const srcIndexCeil = Math.min(srcIndexFloor + 1, inputBuffer.length - 1)
        const t = srcIndex - srcIndexFloor

        // çº¿æ€§æ’å€¼
        output[i] = inputBuffer[srcIndexFloor] * (1 - t) + inputBuffer[srcIndexCeil] * t
    }

    return output
}

/**
 * å°† Float32 éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º 16bit PCM
 */
function float32ToPCM16(float32Array: Float32Array): ArrayBuffer {
    const buffer = new ArrayBuffer(float32Array.length * 2)
    const view = new DataView(buffer)

    for (let i = 0; i < float32Array.length; i++) {
        // é™åˆ¶èŒƒå›´åˆ° [-1, 1]
        const s = Math.max(-1, Math.min(1, float32Array[i]))
        // è½¬æ¢ä¸º 16-bit æ•´æ•°
        const val = s < 0 ? s * 0x8000 : s * 0x7FFF
        view.setInt16(i * 2, val, true) // little-endian
    }

    return buffer
}

/**
 * Robot Audio Bridge Hook
 * 
 * å°† Agent çš„éŸ³é¢‘è¾“å‡ºè½¬å‘åˆ°æœºå™¨äºº
 */
export function useRobotAudioBridge(enabled: boolean = true): RobotAudioBridgeState {
    const room = useRoomContext()

    const wsRef = useRef<WebSocket | null>(null)
    const audioContextRef = useRef<AudioContext | null>(null)
    const processorRef = useRef<ScriptProcessorNode | null>(null)
    const sourceNodeRef = useRef<MediaStreamAudioSourceNode | null>(null)
    const isConnectingRef = useRef(false)
    const hasProcessorRef = useRef(false)

    const [state, setState] = useState<RobotAudioBridgeState>({
        connected: false,
        error: null,
        bytesSent: 0,
    })

    const bytesSentRef = useRef(0)

    // è¿æ¥åˆ°æœºå™¨äºº WebSocketï¼ˆåªè°ƒç”¨ä¸€æ¬¡ï¼‰
    const connectToRobot = useCallback(() => {
        // é˜²æ­¢é‡å¤è¿æ¥
        if (wsRef.current?.readyState === WebSocket.OPEN ||
            wsRef.current?.readyState === WebSocket.CONNECTING ||
            isConnectingRef.current) {
            return
        }

        isConnectingRef.current = true
        console.log('[RobotAudioBridge] Connecting to robot...', ROBOT_WS_URL)

        const ws = new WebSocket(ROBOT_WS_URL)

        ws.onopen = () => {
            console.log('[RobotAudioBridge] Connected to robot!')
            isConnectingRef.current = false
            setState(s => ({ ...s, connected: true, error: null }))
            // é€šçŸ¥æœºå™¨äººå¼€å§‹æ–°æµ
            ws.send(JSON.stringify({ type: 'new_stream' }))
        }

        ws.onclose = () => {
            console.log('[RobotAudioBridge] Disconnected from robot')
            isConnectingRef.current = false
            setState(s => ({ ...s, connected: false }))
            wsRef.current = null
        }

        ws.onerror = (e) => {
            console.error('[RobotAudioBridge] WebSocket error:', e)
            isConnectingRef.current = false
            setState(s => ({ ...s, error: 'Connection failed' }))
        }

        ws.onmessage = (event) => {
            try {
                const msg = JSON.parse(event.data)
                console.log('[RobotAudioBridge] Robot response:', msg)
            } catch {
                // Ignore non-JSON messages
            }
        }

        wsRef.current = ws
    }, [])

    // å‘é€ PCM æ•°æ®åˆ°æœºå™¨äºº
    const sendAudioToRobot = useCallback((pcmData: ArrayBuffer) => {
        if (wsRef.current?.readyState === WebSocket.OPEN) {
            wsRef.current.send(pcmData)
            bytesSentRef.current += pcmData.byteLength

            // æ¯ 50KB æ›´æ–°ä¸€æ¬¡çŠ¶æ€å¹¶æ‰“å°æ—¥å¿—
            if (bytesSentRef.current % 51200 < pcmData.byteLength) {
                console.log(`[RobotAudioBridge] Sent ${(bytesSentRef.current / 1024).toFixed(1)} KB`)
                setState(s => ({ ...s, bytesSent: bytesSentRef.current }))
            }
        }
    }, [])

    // å¤„ç†è¿œç¨‹éŸ³é¢‘è½¨é“
    const processRemoteAudioTrack = useCallback((track: RemoteAudioTrack) => {
        // é˜²æ­¢é‡å¤å¤„ç†
        if (hasProcessorRef.current) {
            console.log('[RobotAudioBridge] Already processing audio, skip')
            return
        }

        hasProcessorRef.current = true
        console.log('[RobotAudioBridge] Processing remote audio track')

        // è·å–éŸ³é¢‘æµ
        const mediaStream = new MediaStream([track.mediaStreamTrack])

        // åˆ›å»º AudioContext
        if (!audioContextRef.current) {
            audioContextRef.current = new AudioContext({ sampleRate: 48000 })
        }
        const audioContext = audioContextRef.current

        // åˆ›å»ºæºèŠ‚ç‚¹
        const source = audioContext.createMediaStreamSource(mediaStream)
        sourceNodeRef.current = source

        // ä½¿ç”¨ ScriptProcessorNode å¤„ç†éŸ³é¢‘
        // ç¼“å†²åŒºå¤§å°ï¼š4096 æ ·æœ¬ â‰ˆ 85ms @ 48kHz
        const processor = audioContext.createScriptProcessor(4096, 1, 1)
        processorRef.current = processor

        let chunkCount = 0
        let totalFrames = 0
        processor.onaudioprocess = (event) => {
            const inputData = event.inputBuffer.getChannelData(0)
            totalFrames++

            // è®¡ç®—éŸ³é¢‘å³°å€¼
            let maxSample = 0
            for (let i = 0; i < inputData.length; i++) {
                const abs = Math.abs(inputData[i])
                if (abs > maxSample) maxSample = abs
            }

            // æ¯ 50 å¸§æ‰“å°ä¸€æ¬¡è°ƒè¯•ä¿¡æ¯ï¼ˆçº¦æ¯ 4 ç§’ï¼‰
            if (totalFrames % 50 === 1) {
                console.log(`[RobotAudioBridge] Frame ${totalFrames}, max sample: ${maxSample.toFixed(6)}, ws: ${wsRef.current?.readyState}`)
            }

            // åªæœ‰æœ‰éŸ³é¢‘æ•°æ®æ‰å‘é€ï¼ˆä½†é˜ˆå€¼é™ä½åˆ°å¯ä»¥æ£€æµ‹åˆ°æå°çš„ä¿¡å·ï¼‰
            if (maxSample < 0.0001) {
                return // å®Œå…¨é™éŸ³æ‰è·³è¿‡
            }

            chunkCount++

            // é‡é‡‡æ ·åˆ° 16kHz
            const resampledData = resampleAudio(
                inputData,
                audioContext.sampleRate,
                TARGET_SAMPLE_RATE
            )

            // è½¬æ¢ä¸º 16bit PCM
            const pcmData = float32ToPCM16(resampledData)

            // å‘é€åˆ°æœºå™¨äºº
            sendAudioToRobot(pcmData)
        }

        // è¿æ¥èŠ‚ç‚¹
        source.connect(processor)
        // åˆ›å»ºä¸€ä¸ªé™éŸ³ç›®æ ‡èŠ‚ç‚¹ï¼Œé¿å…éŸ³é¢‘è¾“å‡ºåˆ°æ‰¬å£°å™¨
        const silentDestination = audioContext.createGain()
        silentDestination.gain.value = 0
        silentDestination.connect(audioContext.destination)
        processor.connect(silentDestination)

        console.log('[RobotAudioBridge] Audio processing started')
    }, [sendAudioToRobot])

    // æ¸…ç†éŸ³é¢‘å¤„ç†å™¨
    const cleanupAudioProcessor = useCallback(() => {
        if (processorRef.current) {
            processorRef.current.disconnect()
            processorRef.current = null
        }
        if (sourceNodeRef.current) {
            sourceNodeRef.current.disconnect()
            sourceNodeRef.current = null
        }
        hasProcessorRef.current = false
    }, [])

    // å»ºç«‹ WebSocket è¿æ¥ï¼ˆåªåœ¨ç»„ä»¶æŒ‚è½½æ—¶ï¼‰
    useEffect(() => {
        if (!enabled) return

        connectToRobot()

        return () => {
            // æ¸…ç† WebSocket
            if (wsRef.current) {
                if (wsRef.current.readyState === WebSocket.OPEN) {
                    wsRef.current.send(JSON.stringify({ type: 'finish' }))
                }
                wsRef.current.close()
                wsRef.current = null
            }
        }
    }, [enabled, connectToRobot])

    // ç›‘å¬è¿œç¨‹å‚ä¸è€…çš„éŸ³é¢‘è½¨é“ï¼ˆç‹¬ç«‹çš„ effectï¼‰
    useEffect(() => {
        if (!enabled || !room) return

        // ç›‘å¬è½¨é“è®¢é˜…äº‹ä»¶
        const handleTrackSubscribed = (
            track: RemoteTrack,
            _publication: any,
            participant: any
        ) => {
            console.log('[RobotAudioBridge] Track subscribed:', track.kind, participant.identity)

            if (track.kind === Track.Kind.Audio) {
                // ç¡®ä¿ WebSocket å·²è¿æ¥
                if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
                    connectToRobot()
                }
                // å¤„ç†éŸ³é¢‘è½¨é“
                processRemoteAudioTrack(track as RemoteAudioTrack)
            }
        }

        const handleTrackUnsubscribed = (track: RemoteTrack) => {
            console.log('[RobotAudioBridge] Track unsubscribed:', track.kind)
            if (track.kind === Track.Kind.Audio) {
                cleanupAudioProcessor()
            }
        }

        room.on(RoomEvent.TrackSubscribed, handleTrackSubscribed)
        room.on(RoomEvent.TrackUnsubscribed, handleTrackUnsubscribed)

        // æ£€æŸ¥å·²å­˜åœ¨çš„éŸ³é¢‘è½¨é“
        room.remoteParticipants.forEach((participant) => {
            participant.audioTrackPublications.forEach((pub) => {
                if (pub.track && pub.isSubscribed) {
                    console.log('[RobotAudioBridge] Found existing audio track')
                    processRemoteAudioTrack(pub.track as RemoteAudioTrack)
                }
            })
        })

        return () => {
            room.off(RoomEvent.TrackSubscribed, handleTrackSubscribed)
            room.off(RoomEvent.TrackUnsubscribed, handleTrackUnsubscribed)
            cleanupAudioProcessor()

            // å…³é—­ AudioContext
            if (audioContextRef.current) {
                audioContextRef.current.close()
                audioContextRef.current = null
            }
        }
    }, [enabled, room, connectToRobot, processRemoteAudioTrack, cleanupAudioProcessor])

    return state
}

/**
 * Robot Audio Bridge ç»„ä»¶
 * 
 * ä½¿ç”¨æ–¹å¼ï¼šåœ¨ LiveKitRoom å†…éƒ¨æ·»åŠ æ­¤ç»„ä»¶
 */
export function RobotAudioBridge({ enabled = true }: { enabled?: boolean }) {
    const state = useRobotAudioBridge(enabled)

    // å¯é€‰ï¼šæ˜¾ç¤ºçŠ¶æ€æŒ‡ç¤ºå™¨
    if (!enabled) return null

    return (
        <div style={{
            position: 'fixed',
            bottom: '10px',
            right: '10px',
            padding: '8px 12px',
            background: state.connected ? 'rgba(74, 222, 128, 0.2)' : 'rgba(239, 68, 68, 0.2)',
            border: `1px solid ${state.connected ? 'rgba(74, 222, 128, 0.4)' : 'rgba(239, 68, 68, 0.4)'}`,
            borderRadius: '8px',
            fontSize: '12px',
            color: state.connected ? '#4ade80' : '#ef4444',
            zIndex: 1000,
        }}>
            ğŸ¤– {state.connected ? 'æœºå™¨äººå·²è¿æ¥' : 'æœºå™¨äººæœªè¿æ¥'}
            {state.connected && state.bytesSent > 0 && (
                <span style={{ marginLeft: '8px', opacity: 0.7 }}>
                    {(state.bytesSent / 1024).toFixed(1)} KB
                </span>
            )}
            {state.error && (
                <span style={{ marginLeft: '8px', color: '#fca5a5' }}>
                    {state.error}
                </span>
            )}
        </div>
    )
}
